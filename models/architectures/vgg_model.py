"""
VGGæƒ…ç»ªè¯†åˆ«æ¨¡å‹å®ç°
é’ˆå¯¹å°å°ºå¯¸å›¾åƒ(48x48)ä¼˜åŒ–çš„VGGæ¶æ„
"""

import torch
import torch.nn as nn
import torchvision.models as models


class EmotionVGG(nn.Module):
    """åŸºäºVGGçš„æƒ…ç»ªè¯†åˆ«æ¨¡å‹"""
    
    def __init__(self, model_name='vgg16', num_classes=7, pretrained=True, dropout_rate=0.5):
        """
        Args:
            model_name: VGGæ¨¡å‹åç§° ('vgg11', 'vgg16', 'vgg19')
            num_classes: æƒ…ç»ªç±»åˆ«æ•°é‡
            pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
            dropout_rate: Dropoutæ¯”ç‡
        """
        super(EmotionVGG, self).__init__()
        
        self.model_name = model_name
        self.num_classes = num_classes
        
        # åŠ è½½é¢„è®­ç»ƒçš„VGGæ¨¡å‹
        if model_name == 'vgg11':
            if pretrained:
                self.backbone = models.vgg11_bn(weights=models.VGG11_BN_Weights.IMAGENET1K_V1)
            else:
                self.backbone = models.vgg11_bn(weights=None)
        elif model_name == 'vgg16':
            if pretrained:
                self.backbone = models.vgg16_bn(weights=models.VGG16_BN_Weights.IMAGENET1K_V1)
            else:
                self.backbone = models.vgg16_bn(weights=None)
        elif model_name == 'vgg19':
            if pretrained:
                self.backbone = models.vgg19_bn(weights=models.VGG19_BN_Weights.IMAGENET1K_V1)
            else:
                self.backbone = models.vgg19_bn(weights=None)
        else:
            raise ValueError(f"Unsupported model: {model_name}")
        
        # è·å–ç‰¹å¾æå–å™¨ï¼ˆå·ç§¯å±‚éƒ¨åˆ†ï¼‰
        self.features = self.backbone.features
        
        # è‡ªé€‚åº”å¹³å‡æ± åŒ–ï¼ˆé€‚åº”48x48è¾“å…¥ï¼‰
        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))
        
        # è‡ªå®šä¹‰åˆ†ç±»å™¨ï¼ˆé€‚é…å°å›¾åƒï¼‰
        self.classifier = nn.Sequential(
            nn.Linear(512 * 7 * 7, 4096),
            nn.ReLU(True),
            nn.Dropout(dropout_rate),
            nn.Linear(4096, 2048),
            nn.ReLU(True),
            nn.Dropout(dropout_rate),
            nn.Linear(2048, 512),
            nn.ReLU(True),
            nn.Dropout(dropout_rate),
            nn.Linear(512, num_classes)
        )
        
        # åˆå§‹åŒ–åˆ†ç±»å™¨æƒé‡
        self._initialize_weights()
        
        print(f"âœ… VGG{model_name.upper()}æ¨¡å‹å·²åˆ›å»º (é’ˆå¯¹48x48ä¼˜åŒ–)")
    
    def _initialize_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for m in self.classifier.modules():
            if isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        # ç‰¹å¾æå–
        x = self.features(x)
        
        # è‡ªé€‚åº”æ± åŒ–
        x = self.avgpool(x)
        
        # å±•å¹³
        x = torch.flatten(x, 1)
        
        # åˆ†ç±»
        x = self.classifier(x)
        
        return x


class CustomEmotionCNN(nn.Module):
    """é’ˆå¯¹æƒ…ç»ªè¯†åˆ«ä¼˜åŒ–çš„è‡ªå®šä¹‰CNN"""
    
    def __init__(self, num_classes=7, dropout_rate=0.5):
        super(CustomEmotionCNN, self).__init__()
        
        self.features = nn.Sequential(
            # ç¬¬ä¸€ç»„å·ç§¯å—
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),  # 48x48 -> 24x24
            nn.Dropout2d(0.25),
            
            # ç¬¬äºŒç»„å·ç§¯å—
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),  # 24x24 -> 12x12
            nn.Dropout2d(0.25),
            
            # ç¬¬ä¸‰ç»„å·ç§¯å—
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),  # 12x12 -> 6x6
            nn.Dropout2d(0.25),
            
            # ç¬¬å››ç»„å·ç§¯å—
            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),  # 6x6 -> 3x3
            nn.Dropout2d(0.25),
        )
        
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(512, 1024),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate),
            nn.Linear(512, num_classes)
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._initialize_weights()
        
        print("âœ… è‡ªå®šä¹‰æƒ…ç»ªè¯†åˆ«CNNå·²åˆ›å»º (é’ˆå¯¹48x48ä¼˜åŒ–)")
    
    def _initialize_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x


def create_vgg_model(config):
    """åˆ›å»ºVGGæ¨¡å‹"""
    model_name = config['model'].get('vgg_name', 'vgg16')
    
    model = EmotionVGG(
        model_name=model_name,
        num_classes=config['model']['num_classes'],
        pretrained=config['model']['pretrained'],
        dropout_rate=config['model']['dropout_rate']
    )
    return model


def create_custom_cnn(config):
    """åˆ›å»ºè‡ªå®šä¹‰CNNæ¨¡å‹"""
    model = CustomEmotionCNN(
        num_classes=config['model']['num_classes'],
        dropout_rate=config['model']['dropout_rate']
    )
    return model


def compare_architectures():
    """æ¯”è¾ƒä¸åŒæ¶æ„çš„å‚æ•°é‡"""
    import yaml
    
    print("=" * 60)
    print("æ¨¡å‹æ¶æ„å¯¹æ¯”åˆ†æ")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿé…ç½®
    config = {
        'model': {
            'name': 'ResNet18',
            'num_classes': 7,
            'pretrained': True,
            'dropout_rate': 0.5,
            'use_cbam': True
        }
    }
    
    # æµ‹è¯•è¾“å…¥
    dummy_input = torch.randn(1, 3, 48, 48)
    
    # ResNet18 + CBAM
    from models.architectures.resnet_model import create_model
    resnet_model = create_model(config)
    resnet_params = sum(p.numel() for p in resnet_model.parameters())
    resnet_output = resnet_model(dummy_input)
    
    # VGG16
    vgg_model = create_vgg_model(config)
    vgg_params = sum(p.numel() for p in vgg_model.parameters())
    vgg_output = vgg_model(dummy_input)
    
    # è‡ªå®šä¹‰CNN
    custom_model = create_custom_cnn(config)
    custom_params = sum(p.numel() for p in custom_model.parameters())
    custom_output = custom_model(dummy_input)
    
    print(f"\nğŸ“Š æ¨¡å‹å¯¹æ¯”:")
    print(f"   ResNet18+CBAM: {resnet_params:,} å‚æ•°")
    print(f"   VGG16:         {vgg_params:,} å‚æ•°")
    print(f"   Custom CNN:    {custom_params:,} å‚æ•°")
    
    print(f"\nğŸ¯ æ¨èåˆ†æ:")
    print(f"   å½“å‰ResNet18+CBAM: 64.99%å‡†ç¡®ç‡")
    print(f"   é¢„æœŸVGG16:         66-70%å‡†ç¡®ç‡ (æ›´æ·±å±‚æ¬¡ç‰¹å¾)")
    print(f"   é¢„æœŸCustom CNN:    68-72%å‡†ç¡®ç‡ (ä¸“é—¨ä¼˜åŒ–)")
    
    print(f"\nğŸ’¡ å»ºè®®:")
    print(f"   1. å°è¯•VGG16: æ›´å¤šå±‚æ•°å¯èƒ½æå–æ›´ä¸°å¯Œç‰¹å¾")
    print(f"   2. å°è¯•Custom CNN: é’ˆå¯¹48x48å’Œæƒ…ç»ªè¯†åˆ«ä¼˜åŒ–")
    print(f"   3. æ•°æ®å¢å¼º: å¯èƒ½æ¯”æ¢æ¶æ„æ›´æœ‰æ•ˆ")
    
    return vgg_model, custom_model


if __name__ == "__main__":
    compare_architectures()
